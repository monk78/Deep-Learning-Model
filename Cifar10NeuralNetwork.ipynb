{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN\n",
    "from keras import initializers\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ...\n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ...\n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ...\n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ...\n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ...\n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ...\n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ...\n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ...\n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ...\n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ...\n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ...\n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ...\n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ...\n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ...\n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ...\n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 35 178 235]\n",
      "   [ 40 176 239]\n",
      "   [ 42 176 241]\n",
      "   ...\n",
      "   [ 99 177 219]\n",
      "   [ 79 147 197]\n",
      "   [ 89 148 189]]\n",
      "\n",
      "  [[ 57 182 234]\n",
      "   [ 44 184 250]\n",
      "   [ 50 183 240]\n",
      "   ...\n",
      "   [156 182 200]\n",
      "   [141 177 206]\n",
      "   [116 149 175]]\n",
      "\n",
      "  [[ 98 197 237]\n",
      "   [ 64 189 252]\n",
      "   [ 69 192 245]\n",
      "   ...\n",
      "   [188 195 206]\n",
      "   [119 135 147]\n",
      "   [ 61  79  90]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73  79  77]\n",
      "   [ 53  63  68]\n",
      "   [ 54  68  80]\n",
      "   ...\n",
      "   [ 17  40  64]\n",
      "   [ 21  36  51]\n",
      "   [ 33  48  49]]\n",
      "\n",
      "  [[ 61  68  75]\n",
      "   [ 55  70  86]\n",
      "   [ 57  79 103]\n",
      "   ...\n",
      "   [ 24  48  72]\n",
      "   [ 17  35  53]\n",
      "   [  7  23  32]]\n",
      "\n",
      "  [[ 44  56  73]\n",
      "   [ 46  66  88]\n",
      "   [ 49  77 105]\n",
      "   ...\n",
      "   [ 27  52  77]\n",
      "   [ 21  43  66]\n",
      "   [ 12  31  50]]]\n",
      "\n",
      "\n",
      " [[[189 211 240]\n",
      "   [186 208 236]\n",
      "   [185 207 235]\n",
      "   ...\n",
      "   [175 195 224]\n",
      "   [172 194 222]\n",
      "   [169 194 220]]\n",
      "\n",
      "  [[194 210 239]\n",
      "   [191 207 236]\n",
      "   [190 206 235]\n",
      "   ...\n",
      "   [173 192 220]\n",
      "   [171 191 218]\n",
      "   [167 190 216]]\n",
      "\n",
      "  [[208 219 244]\n",
      "   [205 216 240]\n",
      "   [204 215 239]\n",
      "   ...\n",
      "   [175 191 217]\n",
      "   [172 190 216]\n",
      "   [169 191 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[207 199 181]\n",
      "   [203 195 175]\n",
      "   [203 196 173]\n",
      "   ...\n",
      "   [135 132 127]\n",
      "   [162 158 150]\n",
      "   [168 163 151]]\n",
      "\n",
      "  [[198 190 170]\n",
      "   [189 181 159]\n",
      "   [180 172 147]\n",
      "   ...\n",
      "   [178 171 160]\n",
      "   [175 169 156]\n",
      "   [175 169 154]]\n",
      "\n",
      "  [[198 189 173]\n",
      "   [189 181 162]\n",
      "   [178 170 149]\n",
      "   ...\n",
      "   [195 184 169]\n",
      "   [196 189 171]\n",
      "   [195 190 171]]]\n",
      "\n",
      "\n",
      " [[[229 229 239]\n",
      "   [236 237 247]\n",
      "   [234 236 247]\n",
      "   ...\n",
      "   [217 219 233]\n",
      "   [221 223 234]\n",
      "   [222 223 233]]\n",
      "\n",
      "  [[222 221 229]\n",
      "   [239 239 249]\n",
      "   [233 234 246]\n",
      "   ...\n",
      "   [223 223 236]\n",
      "   [227 228 238]\n",
      "   [210 211 220]]\n",
      "\n",
      "  [[213 206 211]\n",
      "   [234 232 239]\n",
      "   [231 233 244]\n",
      "   ...\n",
      "   [220 220 232]\n",
      "   [220 219 232]\n",
      "   [202 203 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150 143 135]\n",
      "   [140 135 127]\n",
      "   [132 127 120]\n",
      "   ...\n",
      "   [224 222 218]\n",
      "   [230 228 225]\n",
      "   [241 241 238]]\n",
      "\n",
      "  [[137 132 126]\n",
      "   [130 127 120]\n",
      "   [125 121 115]\n",
      "   ...\n",
      "   [181 180 178]\n",
      "   [202 201 198]\n",
      "   [212 211 207]]\n",
      "\n",
      "  [[122 119 114]\n",
      "   [118 116 110]\n",
      "   [120 116 111]\n",
      "   ...\n",
      "   [179 177 173]\n",
      "   [164 164 162]\n",
      "   [163 163 161]]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4,input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_12 to have 2 dimensions, but got array with shape (50000, 10, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-078f77d19f47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_12 to have 2 dimensions, but got array with shape (50000, 10, 10)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
